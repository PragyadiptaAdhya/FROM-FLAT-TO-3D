{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "i35n-TSfWvoO"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import os\n",
        "import numpy as np\n",
        "import open3d as o3d\n",
        "from PIL import Image\n",
        "from transformers import pipeline\n",
        "from tqdm import tqdm\n",
        "from copy import deepcopy\n",
        "from sklearn.neighbors import KDTree\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQD-5MXLqpFR"
      },
      "source": [
        "##Frame maker\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cyRXP2tjWzSC"
      },
      "outputs": [],
      "source": [
        "video_path = \"<Video IN>\"\n",
        "output_folder = \"<Output folder for the frames>\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "save_fps = 0.5  #\n",
        "\n",
        "\n",
        "cap = cv2.VideoCapture(video_path)\n",
        "fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "\n",
        "\n",
        "frame_interval = int(fps / save_fps)\n",
        "\n",
        "frame_count = 0\n",
        "saved_count = 0\n",
        "\n",
        "while True:\n",
        "    ret, frame = cap.read()\n",
        "    if not ret:\n",
        "        break\n",
        "\n",
        "\n",
        "    if frame_count % frame_interval == 0:\n",
        "        frame_name = f\"{output_folder}/frame_{saved_count:05d}.jpg\"\n",
        "        cv2.imwrite(frame_name, frame)\n",
        "        saved_count += 1\n",
        "\n",
        "    frame_count += 1\n",
        "\n",
        "cap.release()\n",
        "print(f\" Saved {saved_count} frames at {save_fps} fps from video.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZkclAETqrmP"
      },
      "source": [
        "##Frame to depth map and cloud"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BK5HLJxiXZu-"
      },
      "outputs": [],
      "source": [
        "frames_folder = \"<Input folder for frames>\"\n",
        "depth_folder = \"<Output folder for the depth map>\"\n",
        "pcd_folder = \"<Output folder for the point clouds>\"\n",
        "\n",
        "os.makedirs(depth_folder, exist_ok=True)\n",
        "os.makedirs(pcd_folder, exist_ok=True)\n",
        "\n",
        "\n",
        "depth_estimator = pipeline(\"depth-estimation\", model=\"Intel/dpt-large\")\n",
        "\n",
        "\n",
        "fx = fy = 1100\n",
        "\n",
        "\n",
        "for filename in tqdm(sorted(os.listdir(frames_folder))):\n",
        "    if not (filename.lower().endswith(\".jpg\") or filename.lower().endswith(\".png\")):\n",
        "        continue\n",
        "\n",
        "    image_path = os.path.join(frames_folder, filename)\n",
        "    frame = cv2.imread(image_path)\n",
        "    if frame is None:\n",
        "        print(f\" Could not read image: {filename}\")\n",
        "        continue\n",
        "\n",
        "    height, width = frame.shape[:2]\n",
        "    rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "    rgb_pil = Image.fromarray(rgb)\n",
        "    cx = width / 2\n",
        "    cy = height / 2\n",
        "\n",
        "\n",
        "    depth_output = depth_estimator(rgb_pil)\n",
        "    depth_array = np.array(depth_output[\"depth\"], dtype=np.float32)\n",
        "\n",
        "    scale_factor = 25.0\n",
        "    depth_scaled = depth_array / depth_array.max() * scale_factor\n",
        "\n",
        "    alpha = 50.0\n",
        "    depth_log = np.log1p(alpha * depth_scaled)\n",
        "\n",
        "    depth_vis = cv2.normalize(depth_log, None, 0, 255, cv2.NORM_MINMAX)\n",
        "    depth_vis = depth_vis.astype(np.uint8)\n",
        "    depth_path = os.path.join(depth_folder, f\"{os.path.splitext(filename)[0]}_depth.png\")\n",
        "    cv2.imwrite(depth_path, depth_vis)\n",
        "\n",
        "    u, v = np.meshgrid(np.arange(width), np.arange(height))\n",
        "    X = (u - cx) / fx * depth_log.max()\n",
        "    Y = (v - cy) / fy * depth_log.max()\n",
        "    Z = depth_log\n",
        "\n",
        "    points = np.stack([X.flatten(), Y.flatten(), Z.flatten()], axis=-1)\n",
        "    colors = rgb.reshape(-1, 3) / 255.0\n",
        "\n",
        "    pcd = o3d.geometry.PointCloud()\n",
        "    pcd.points = o3d.utility.Vector3dVector(points)\n",
        "    pcd.colors = o3d.utility.Vector3dVector(colors)\n",
        "\n",
        "\n",
        "    pcd.transform([[-1, 0, 0, 0],\n",
        "                   [0, -1, 0, 0],\n",
        "                   [0,  0, 1, 0],\n",
        "                   [0,  0, 0, 1]])\n",
        "\n",
        "\n",
        "    pcd_path = os.path.join(pcd_folder, f\"{os.path.splitext(filename)[0]}_cloud.ply\")\n",
        "    o3d.io.write_point_cloud(pcd_path, pcd)\n",
        "\n",
        "\n",
        "print(\"\\n All frames processed successfully!\")\n",
        "print(f\"Depth maps saved to: {depth_folder}\")\n",
        "print(f\"Point clouds saved to: {pcd_folder}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_nYLYHBAsXBW"
      },
      "source": [
        "\n",
        "\n",
        "##Working with ICP threshold 0.3\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I6bULGcoO7Lz"
      },
      "outputs": [],
      "source": [
        "pcd_folder = \"<Individual point clouds folder> \"\n",
        "output_folder = \"<Output folder for merged clouds>\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "voxel_size = 0.02\n",
        "fgr_distance_mul = 5.0\n",
        "icp_distance_mul = 2.0\n",
        "fitness_threshold = 0.3\n",
        "save_every = 2\n",
        "visualize_steps = False\n",
        "\n",
        "\n",
        "def preprocess(pcd, voxel_size):\n",
        "    pcd_down = pcd.voxel_down_sample(voxel_size)\n",
        "    pcd_down.estimate_normals(\n",
        "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
        "    fpfh = o3d.pipelines.registration.compute_fpfh_feature(\n",
        "        pcd_down,\n",
        "        o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*5, max_nn=100)\n",
        "    )\n",
        "    return pcd_down, fpfh\n",
        "\n",
        "def register_pair(src, tgt, voxel_size):\n",
        "    src_down, src_fpfh = preprocess(src, voxel_size)\n",
        "    tgt_down, tgt_fpfh = preprocess(tgt, voxel_size)\n",
        "    distance_threshold = voxel_size * fgr_distance_mul\n",
        "    fgr_option = o3d.pipelines.registration.FastGlobalRegistrationOption(\n",
        "        maximum_correspondence_distance=distance_threshold)\n",
        "    fgr_result = o3d.pipelines.registration.registration_fgr_based_on_feature_matching(\n",
        "        src_down, tgt_down, src_fpfh, tgt_fpfh, fgr_option\n",
        "    )\n",
        "    icp_thresh = voxel_size * icp_distance_mul\n",
        "    src.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
        "    tgt.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
        "    icp_result = o3d.pipelines.registration.registration_icp(\n",
        "        src, tgt, icp_thresh, fgr_result.transformation,\n",
        "        o3d.pipelines.registration.TransformationEstimationPointToPlane(),\n",
        "        o3d.pipelines.registration.ICPConvergenceCriteria(max_iteration=50)\n",
        "    )\n",
        "    return icp_result.transformation, icp_result.fitness\n",
        "\n",
        "\n",
        "files = sorted([f for f in os.listdir(pcd_folder) if f.endswith(\".ply\")])\n",
        "print(files)\n",
        "pcds = [o3d.io.read_point_cloud(os.path.join(pcd_folder, f)) for f in files]\n",
        "print(f\"Loaded {len(pcds)} point clouds.\")\n",
        "\n",
        "merged = deepcopy(pcds[0])\n",
        "o3d.io.write_point_cloud(os.path.join(output_folder, f\"merged_1.ply\"), merged)\n",
        "\n",
        "for i in range(1, len(pcds)):\n",
        "    source = deepcopy(pcds[i])\n",
        "    print(f\"\\n Aligning {files[i]} to merged scene...\")\n",
        "\n",
        "    transformation, fitness = register_pair(source, merged, voxel_size)\n",
        "    print(f\" ICP Fitness: {fitness:.4f}\")\n",
        "\n",
        "    if fitness >= fitness_threshold:\n",
        "        print(f\" Merging {files[i]} (fitness â‰¥ {fitness_threshold})\")\n",
        "        source.transform(transformation)\n",
        "        merged += source\n",
        "    else:\n",
        "        print(f\" Skipping {files[i]} (fitness {fitness:.4f} < {fitness_threshold})\")\n",
        "\n",
        "\n",
        "    if (i + 1) % save_every == 0 or (i + 1) == len(pcds):\n",
        "        merged_path = os.path.join(output_folder, f\"merged_up_to_{i+1}.ply\")\n",
        "        merged_down = merged.voxel_down_sample(voxel_size/2)\n",
        "        merged_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
        "        o3d.io.write_point_cloud(merged_path, merged_down)\n",
        "        print(f\" Saved intermediate merged cloud: {merged_path}\")\n",
        "\n",
        "\n",
        "final_path = os.path.join(output_folder, \"<Final merged cloud name> \")\n",
        "merged_down = merged.voxel_down_sample(voxel_size/2)\n",
        "merged_down.estimate_normals(o3d.geometry.KDTreeSearchParamHybrid(radius=voxel_size*2, max_nn=30))\n",
        "o3d.io.write_point_cloud(final_path, merged_down)\n",
        "print(f\"\\n Final merged cloud saved to: {final_path}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In case you want a smoothened cloud"
      ],
      "metadata": {
        "id": "awu1ra87G2bC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "pcd = o3d.io.read_point_cloud(\"<Input point cloud to smoothen>\")\n",
        "print(\"And reached here\")\n",
        "print(\"Original points:\", len(pcd.points))\n",
        "\n",
        "\n",
        "pcd, ind = pcd.remove_statistical_outlier(nb_neighbors=30, std_ratio=2.0)\n",
        "pcd, ind = pcd.remove_radius_outlier(nb_points=20, radius=0.03)\n",
        "pcd = pcd.voxel_down_sample(voxel_size=0.01)\n",
        "print(\"After filtering and downsampling:\", len(pcd.points))\n",
        "\n",
        "\n",
        "pcd.estimate_normals(search_param=o3d.geometry.KDTreeSearchParamKNN(knn=30))\n",
        "\n",
        "\n",
        "mesh, densities = o3d.geometry.TriangleMesh.create_from_point_cloud_poisson(\n",
        "    pcd, depth=10\n",
        ")\n",
        "\n",
        "mask = densities < np.quantile(densities, 0.03)\n",
        "mesh.remove_vertices_by_mask(mask)\n",
        "\n",
        "\n",
        "mesh = mesh.filter_smooth_simple(number_of_iterations=5)\n",
        "mesh.compute_vertex_normals()\n",
        "\n",
        "\n",
        "o3d.io.write_triangle_mesh(\"<Final merged cloud path to be added here>\", mesh)\n",
        "print(\"Mesh vertices:\", len(mesh.vertices))\n",
        "print(\"Mesh faces:\", len(mesh.triangles))\n",
        "print(\"Mesh has colors?\", mesh.has_vertex_colors())\n",
        "o3d.visualization.draw_geometries([mesh])\n"
      ],
      "metadata": {
        "id": "j2K6q8qBOgIv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Projection Error Mean and Median"
      ],
      "metadata": {
        "id": "KeVpaABM9-oU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_reprojection_error(pcd_file, rgb_file,\n",
        "                               fx, fy, cx, cy,\n",
        "                               R=np.eye(3), t=np.zeros((3,1))):\n",
        "\n",
        "    pcd = o3d.io.read_point_cloud(pcd_file)\n",
        "    points = np.asarray(pcd.points)\n",
        "    if points.shape[0] == 0:\n",
        "        raise ValueError(f\"Point cloud {pcd_file} is empty.\")\n",
        "\n",
        "    img = cv2.imread(rgb_file, cv2.IMREAD_GRAYSCALE)\n",
        "    if img is None:\n",
        "        raise FileNotFoundError(f\"Could not load image: {rgb_file}\")\n",
        "\n",
        "    edges = cv2.Canny(img, 80, 160)\n",
        "    edge_pixels = np.column_stack(np.where(edges > 0))\n",
        "    edge_pixels = np.fliplr(edge_pixels)\n",
        "\n",
        "    if edge_pixels.shape[0] < 10:\n",
        "        raise ValueError(f\"Not enough edges in image: {rgb_file}\")\n",
        "\n",
        "    tree = KDTree(edge_pixels)\n",
        "\n",
        "\n",
        "    pts_cam = (R @ points.T + t).T\n",
        "    pts_cam = pts_cam[pts_cam[:, 2] > 0]\n",
        "\n",
        "    x_proj = (fx * pts_cam[:, 0] / pts_cam[:, 2]) + cx\n",
        "    y_proj = (fy * pts_cam[:, 1] / pts_cam[:, 2]) + cy\n",
        "    proj_2d = np.vstack((x_proj, y_proj)).T\n",
        "\n",
        "\n",
        "    distances, _ = tree.query(proj_2d, k=1)\n",
        "    mean_error = float(np.mean(distances))\n",
        "    median_error = float(np.median(distances))\n",
        "\n",
        "    return mean_error, median_error\n",
        "\n",
        "\n",
        "pcd_folder = \"<Point Cloud folder>\"\n",
        "rgb_folder = \"<RGB Image folder>\"\n",
        "\n",
        "\n",
        "pcd_files = sorted([f for f in os.listdir(pcd_folder) if f.endswith(\".ply\")])\n",
        "rgb_files = sorted([f for f in os.listdir(rgb_folder) if f.lower().endswith((\".jpg\",\".png\"))])\n",
        "\n",
        "mean_errors = []\n",
        "median_errors = []\n",
        "\n",
        "# These are for the device my data was captured in. Please change according to your needs\n",
        "fx, fy = 1100, 1100\n",
        "cx, cy = 1080/2, 1920/2\n",
        "\n",
        "for pcd_name, rgb_name in zip(pcd_files, rgb_files):\n",
        "    pcd_path = os.path.join(pcd_folder, pcd_name)\n",
        "    rgb_path = os.path.join(rgb_folder, rgb_name)\n",
        "\n",
        "    try:\n",
        "        mean_err, med_err = compute_reprojection_error(\n",
        "            pcd_path, rgb_path, fx, fy, cx, cy\n",
        "        )\n",
        "        mean_errors.append(mean_err)\n",
        "        median_errors.append(med_err)\n",
        "    except Exception as e:\n",
        "        print(f\"Skipped {pcd_name} / {rgb_name}: {e}\")\n",
        "\n",
        "overall_mean = np.mean(mean_errors)\n",
        "overall_median = np.median(median_errors)\n",
        "\n",
        "print(f\"Mean: {overall_mean:.2f}px\")\n",
        "print(f\"Median: {overall_median:.2f}px\")\n"
      ],
      "metadata": {
        "id": "j8keeUKx9_jU"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
